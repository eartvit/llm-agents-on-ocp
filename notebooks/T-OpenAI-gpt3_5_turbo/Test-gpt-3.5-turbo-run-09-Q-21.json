{"final_response": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17847 tokens (16177 in the messages, 1670 in the functions). Please reduce the length of the messages or functions.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "total_tokens": 0, "total_time_seconds": 3.3537306785583496, "msg_sequence": ["Exception in process_request: local variable 'messages' referenced before assignment"], "ai_tool_calls": {"name": "AI_exception"}, "tool_call_responses": {}}