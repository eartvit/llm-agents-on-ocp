{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae495c1-6c81-4012-993f-34da0c1c9943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import LLM libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a46297-93ad-40ee-af1b-6d1d7f551c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb280a-566f-4a28-aef7-034184d1eddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d88a6-ec94-4be1-a031-e1ed3870e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f65d5-bbb4-48c3-a8df-0acd5886ce20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647c94e-ceae-4556-984a-af75e48287fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"LLM_TEST-gpt4-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae10bc9-7ceb-4916-80ba-6348ac3e1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fb10a-21b4-42d0-b463-9cd8a5bac833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bad18f-6f76-4ad6-8cff-4fb0fbeb36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=model, temperature=0, api_key=\"set_your_key_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04905576-2e11-40b9-9bf2-c75e9c6a4690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_runs = [str(i).zfill(2) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b371591-dcc3-4fb7-a6aa-b8958a86bb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../tool_list_operators-struct.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f99eb-322d-41bf-a8bc-618e8b38c523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../tool_summarize_states-struct.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f81cc3-0ffe-4ca5-b71d-b24254cf1a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../tool_prometheus-struct.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ed323-e2ff-4a79-a728-114c091f7419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../tool_mlasp-struct.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32a1fa-7a6c-4d2a-9668-67c8ed98e7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5586a07-7e0a-4d26-b45e-a645e17e61cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../tool_rag-struct.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402af5fc-4bdd-42c3-9035-361c56230c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tools = [TavilySearchResults(max_results=1), tool_operators_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea471374-6be1-4e56-844c-693206d81b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [tool_operators_list,\n",
    "         tool_namespace_pods_summary, tool_namespace_svc_summary, \n",
    "         tool_prometheus_all_metrics, tool_prometheus_metric_range, tool_time_value,\n",
    "         tool_plot_prometheus_metric_range_as_file,\n",
    "         tool_mlasp_config,\n",
    "         tool_retriever\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e1214-b931-4c42-bfef-38d611ce864c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys_message = SystemMessage(content=\"You are a helpfull assistant called Dave.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c6450-4d27-4b5e-bbaf-3716ed0c66db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_react_chat = create_react_agent(llm, tools, state_modifier=sys_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917064f0-d39b-4b4e-ad06-55be24f0d5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = {\n",
    "    \"Q-01\": \"Hi, who are you?\",\n",
    "    \"Q-02\": \"What tools do you have access to?\",\n",
    "    \"Q-03\": \"Give me the list of tools you have access to.\",\n",
    "    \"Q-04\": \"Give me the list and a short description of the tools you have access to.\",\n",
    "    \"Q-05\": \"What operators are in namespace demo?\",\n",
    "    \"Q-06\": \"What operators are in namespace demo? Please provide only the name and the version for each operator.\",\n",
    "    \"Q-07\": \"How can I create a Data Science Project?\",\n",
    "    \"Q-08\": \"Can you describe Paris in 100 words or less?\",\n",
    "    \"Q-09\": \"Is there a river?\",\n",
    "    \"Q-10\": \"Tell me about the pods in namespace demo.\",\n",
    "    \"Q-11\": \"Give me a summary of the running pods in namespace demo. Please include service and route information in the response.\",\n",
    "    \"Q-12\": \"Give me the complete summary of the pods in namespace demo.\",\n",
    "    \"Q-13\": \"Give me a summary of the running pods in namespace demo. Give me only the names and the route if they have one.\",\n",
    "    \"Q-14\": \"What day is today?\",\n",
    "    \"Q-15\": \"What is the current date time?\",\n",
    "    \"Q-16\": \"What is the current timestamp?\",\n",
    "    \"Q-17\": \"What is the timestamp and date time for 3 hours ago?\",\n",
    "    \"Q-18\": \"What is the timestamp and date time for 3 hours from now?\",\n",
    "    \"Q-19\": \"What is the timestamp and date time for 3 hours ago?\",\n",
    "    \"Q-20\": \"Is there a prometheus service running in namespace demo? If so, give me its name and port values.\",\n",
    "    \"Q-21\": \"Find out the service name and port number of the Prometheus service running in namespace demo. Then use that information to retrieve the list of metrics filtered by namespace demo.\",\n",
    "    \"Q-22\": \"Find out the Prometheus service name and port number running in namespace demo. Give me all the metrics stored by it that have a name that starts with load_generator.\",\n",
    "    \"Q-23\": \"What configuration of WireMock supports a throughput KPI of 307 within a 2.9 percent precision? Search for 100 epochs to find the result.\",\n",
    "    \"Q-24\": \"Find out the Prometheus service name and port number running in namespace demo. Use it to to plot all the prometheus metric data for the metric load_generator_total_msg starting 40 days ago until now. Return only the file name and nothing else.\",\n",
    "    \"Q-25\": \"Find out the Prometheus service name and port number running in namespace demo. Use that to get all the prometheus metric data for the metric load_generator_total_msg starting 40 days ago until now. Print out only the metric values and their associated timestamp as a CSV table.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57689fa-469b-492a-bcc9-f1379c90683c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_request(request):\n",
    "    \"\"\"\n",
    "    Process an LLM agent request/response.\n",
    "    :param request: the request to pass on to the LLM agent\n",
    "    :return: a dictionary with various metadata \n",
    "    \"\"\"\n",
    "    is_success = 0\n",
    "    start = time.time()\n",
    "    final_response = \"\"\n",
    "\n",
    "    try:\n",
    "        messages = agent_react_chat.invoke({\"messages\": [(\"user\", request)]})\n",
    "        stop = time.time()\n",
    "        is_success = 1\n",
    "    except Exception as e:\n",
    "        final_response = str(e)\n",
    "        stop = time.time()\n",
    "\n",
    "    elapsed = stop-start\n",
    "    metadata = {}\n",
    "\n",
    "    try:\n",
    "        total_tokens = 0\n",
    "        msg_counter = 1\n",
    "        msg_sequence = []\n",
    "        ai_tool_calls = {}\n",
    "        tool_call_responses = {}\n",
    "\n",
    "        for msg in messages[\"messages\"]:\n",
    "            msg_sequence.append(str(type(msg)))\n",
    "            if isinstance(msg, AIMessage):\n",
    "                t_call = {\"name\": \"AI_did_not_call_any_tools\"}\n",
    "                for item in msg.tool_calls:\n",
    "                    t_call = item\n",
    "                ai_tool_calls[msg_counter] = t_call\n",
    "                msg_counter += 1\n",
    "                total_tokens += msg.usage_metadata[\"total_tokens\"]\n",
    "            if isinstance(msg, ToolMessage):\n",
    "                tool_call_responses[msg.tool_call_id] = msg.content\n",
    "\n",
    "        if is_success == 1:\n",
    "            final_response = messages[\"messages\"][-1].content\n",
    "\n",
    "        metadata['final_response'] = final_response\n",
    "        metadata['total_tokens'] = total_tokens\n",
    "        metadata['total_time_seconds'] = elapsed\n",
    "        metadata['msg_sequence'] = msg_sequence\n",
    "        metadata['ai_tool_calls'] = ai_tool_calls\n",
    "        metadata['tool_call_responses'] = tool_call_responses\n",
    "\n",
    "    except Exception as e:\n",
    "        metadata['final_response'] = final_response\n",
    "        metadata['total_tokens'] = 0\n",
    "        metadata['total_time_seconds'] = elapsed\n",
    "        metadata['msg_sequence'] = ['Exception in process_request: '+str(e)]\n",
    "        metadata['ai_tool_calls'] = {\"name\": \"AI_exception\"}\n",
    "        metadata['tool_call_responses'] = {}\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a695f-0873-4a33-b0e4-e5a455a9068d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iteration_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5543a8b-6ee5-4b9e-8fa0-cce5ea09a9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for iteration in tqdm(test_runs):\n",
    "    test_run_summary = {}\n",
    "    for key in tqdm(questions):\n",
    "        result = process_request(questions[key])\n",
    "\n",
    "        fname = f'Test-{model}-run-{iteration}-{key}.json'\n",
    "\n",
    "        with open(fname, 'w') as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "        metadata = {}\n",
    "        metadata['total_tokens'] = result['total_tokens']\n",
    "        metadata['total_time_seconds'] = result['total_time_seconds']\n",
    "        metadata['final_response'] = result['final_response']\n",
    "        test_run_summary[key] = metadata\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(test_run_summary, orient=\"index\")\n",
    "    dframe_fname = f\"Test-summary-{model}-iteration-{iteration}.csv\"\n",
    "    dframe.to_csv(dframe_fname, header=True)\n",
    "\n",
    "    iteration_summary[iteration] = test_run_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af86886-5815-44ca-9c52-c3c5a98f3808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_summary = pd.DataFrame.from_dict(iteration_summary, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800b34b-ca64-43c0-986d-cf0a5e796fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c6e47-398d-45eb-ae3b-915c8abd2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe_summary.to_csv(f\"test-all-runs-{model}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21a4dd-66d2-4662-b134-89f466c0e441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iteration_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0c14-22e4-454c-867f-bda4598282be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_summary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcc9f2-4fcf-4b2e-b05c-6d5979e2e28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_summary.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a39e1b-3074-4727-bb53-ae97cc9733da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in dframe_summary.columns:\n",
    "    df = pd.json_normalize(dframe_summary[column])\n",
    "    df.columns = [f'{column}-' + str(col) for col in df.columns]\n",
    "    dframe_summary = pd.concat([dframe_summary.drop([column], axis = 1), df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f670ac4-c17e-4cc7-be67-a44528977f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdf7f7-c18f-4d12-a259-95950910ebce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_summary.to_csv(f\"test-all-runs-expanded-{model}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddf854-c329-40ad-8247-2b3ce6d00269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregation = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381272da-40bc-48fc-bf62-3b5c5c4c7e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in dframe_summary.columns:\n",
    "    if 'total_tokens' in column:\n",
    "        aggregation[f'average-{column}'] = dframe_summary[column].mean()\n",
    "\n",
    "    if 'total_time_seconds' in column:\n",
    "        aggregation[f'p50-{column}'] = dframe_summary[column].quantile(0.5)\n",
    "        aggregation[f'p90-{column}'] = dframe_summary[column].quantile(0.9)\n",
    "        aggregation[f'max-{column}'] = dframe_summary[column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4c5dc-2acf-465f-a51c-909e530906a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "element = {}\n",
    "element[0] = aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8115e-7799-4c65-b1b5-cd7399e8867a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_aggregation = pd.DataFrame.from_dict(element, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e08e6a-6b6f-47e1-b689-7b6058cee7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d128ec7-5ba0-46c7-b7d8-d9badc793021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dframe_aggregation.to_csv(f\"test-all-runs-aggregated-{model}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccf8e2-6518-49be-ac0a-91723d77d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2254e-3f6e-4487-b59a-eed14cb90df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe_aggregation = pd.read_csv(\"test-all-runs-aggregated-gpt-4-turbo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f123f5-406d-4101-a26d-fe460ece1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe_aggregation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908dd0a-ba8b-4282-b23a-2da18b3688fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch-GPU",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
